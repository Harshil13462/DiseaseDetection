{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe7yGbZkCDYg",
        "outputId": "d384f61b-f542-464b-e383-f89c33bc1ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import PIL\n",
        "from google.colab.patches import cv2_imshow\n",
        "import gspread\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import sklearn\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXGcu7NcUrIp"
      },
      "outputs": [],
      "source": [
        "NoFind = 0\n",
        "Covid = 1\n",
        "Atelectasis = 3\n",
        "Cardiomegaly = 4\n",
        "Effusion = 5\n",
        "Infiltration = 6\n",
        "MASS = 7\n",
        "Nodule = 8\n",
        "Pneumonia = 9\n",
        "Pneumothorax = 10\n",
        "Consolidation = 11\n",
        "Edema = 12\n",
        "Emphysema, Fibrosis, Pleural, Hernia, Tuberculosis, Opacity, Other = 13, 14, 15, 16, 17, 18, 19\n",
        "testing_path = '/content/gdrive/MyDrive/DiseaseDetection/Testing/Images/'\n",
        "\n",
        "tb_path_pos = '/content/gdrive/MyDrive/DiseaseDetection/TB_Chest_Radiography_Database/Tuberculosis/'\n",
        "tb_path_neg = '/content/gdrive/MyDrive/DiseaseDetection/TB_Chest_Radiography_Database/Normal/'\n",
        "tb_data = '/content/gdrive/MyDrive/DiseaseDetection/TB_Chest_Radiography_Database/Tuberculosis.csv'\n",
        "\n",
        "cov1_path_cov = '/content/gdrive/MyDrive/DiseaseDetection/COVID-19_Radiography_Dataset/COVID/images/'\n",
        "cov1_path_vir = '/content/gdrive/MyDrive/DiseaseDetection/COVID-19_Radiography_Dataset/Viral Pneumonia/images/'\n",
        "cov1_path_opac = '/content/gdrive/MyDrive/DiseaseDetection/COVID-19_Radiography_Dataset/Lung_Opacity/images/'\n",
        "cov1_path_neg = '/content/gdrive/MyDrive/DiseaseDetection/COVID-19_Radiography_Dataset/Normal/images/'\n",
        "cov1_data = '/content/gdrive/MyDrive/DiseaseDetection/COVID-19_Radiography_Dataset/data.csv'\n",
        "\n",
        "cov2_images = '/content/gdrive/MyDrive/DiseaseDetection/covid-chestxray-dataset-master/images/'\n",
        "cov2_data = '/content/gdrive/MyDrive/DiseaseDetection/covid-chestxray-dataset-master/Data.csv'\n",
        "\n",
        "dd_paths = []\n",
        "for i in range(1, 13):\n",
        "  x = '/content/gdrive/MyDrive/DiseaseDetection/DD Full Dataset/images_0'\n",
        "  if i < 10:\n",
        "    x += '0'\n",
        "  x += str(i) + '/images/'\n",
        "  dd_paths.append(x)\n",
        "\n",
        "dd_data = '/content/gdrive/MyDrive/DiseaseDetection/DD Full Dataset/data.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pi1ao1U-UsLK"
      },
      "outputs": [],
      "source": [
        "tb_df = pd.read_csv(tb_data)\n",
        "cov1_df = pd.read_csv(cov1_data)\n",
        "cov2_df = pd.read_csv(cov2_data)\n",
        "dd_df = pd.read_csv(dd_data)\n",
        "\n",
        "tb_df.rename(columns = {\"FILE NAME\": \"Name\"}, inplace = True)\n",
        "cov1_df.rename(columns = {\"FILE NAME\": \"Name\"}, inplace = True)\n",
        "cov2_df.rename(columns = {\"filename\": \"Name\", 'finding': 'Diagnosis'}, inplace = True)\n",
        "dd_df.rename(columns = {\"Image Index\": \"Name\", 'Finding Labels': 'Diagnosis'}, inplace = True)\n",
        "\n",
        "def split(x):\n",
        "  if \"|\" in x:\n",
        "    return x.split('|')\n",
        "  elif \"/\" in x:\n",
        "    return x.split('/')\n",
        "  else:\n",
        "    if type(x) != list:\n",
        "      return [x]\n",
        "    else:\n",
        "      return x\n",
        "def organize(x):\n",
        "  for i in range(len(x)):\n",
        "    if x[i].lower() == \"covid\" or x[i].lower() == \"covid-19\":\n",
        "      x[i] = Covid\n",
        "    elif x[i] == \"None\" or x[i] == \"No Finding\":\n",
        "      x[i] = NoFind\n",
        "    elif x[i] == \"Viral\":\n",
        "      x[i] = Pneumonia\n",
        "    elif x[i] == \"Atelectasis\":\n",
        "      x[i] = Atelectasis\n",
        "    elif x[i] == \"Cardiomegaly\":\n",
        "      x[i] = Cardiomegaly\n",
        "    elif x[i] == \"Effusion\":\n",
        "      x[i] = Effusion\n",
        "    elif x[i] == \"Infiltration\":\n",
        "      x[i] = Infiltration\n",
        "    elif x[i] == \"Mass\":\n",
        "      x[i] = MASS\n",
        "    elif x[i] == \"Nodule\":\n",
        "      x[i] = Nodule\n",
        "    elif x[i] == \"Pneumonia\":\n",
        "      x[i] = Pneumonia\n",
        "    elif x[i] == \"Pneumothorax\":\n",
        "      x[i] = Pneumothorax\n",
        "    elif x[i] == \"Consolidation\":\n",
        "      x[i] = Consolidation\n",
        "    elif x[i] == \"Edema\":\n",
        "      x[i] = Edema\n",
        "    elif x[i] == \"Emphysema\":\n",
        "      x[i] = Emphysema\n",
        "    elif x[i] == \"Fibrosis\":\n",
        "      x[i] = Fibrosis\n",
        "    elif x[i] == \"Pleural_Thickening\":\n",
        "      x[i] = Pleural\n",
        "    elif x[i] == \"Hernia\":\n",
        "      x[i] = Hernia\n",
        "    elif x[i] == \"Tuberculosis\":\n",
        "      x[i] = Tuberculosis\n",
        "    elif x[i] == \"Opacity\":\n",
        "      x[i] = Opacity\n",
        "    else:\n",
        "      x[i] = Other\n",
        "  return x\n",
        "def cov1_modify(x):\n",
        "  if \"NORMAL\" in x:\n",
        "    return x.capitalize() + '.png'\n",
        "  return x + '.png'\n",
        "\n",
        "def tb_modify(x):\n",
        "  if \"Normal\" in x:\n",
        "    return \"Normal TB-\" + x.split(\"-\")[1] + '.png'\n",
        "  return x + \".png\"\n",
        "cov1_df[\"Name\"] = cov1_df[\"Name\"].apply(cov1_modify)\n",
        "tb_df[\"Name\"] = tb_df[\"Name\"].apply(tb_modify)\n",
        "\n",
        "\n",
        "df = pd.concat([dd_df, cov2_df, cov1_df, tb_df], ignore_index=True)\n",
        "df[\"Diagnosis\"] = df[\"Diagnosis\"].apply(split)\n",
        "df[\"Diagnosis\"] = df[\"Diagnosis\"].apply(organize)\n",
        "df.rename(columns = {\"Name\": \"Image Name\", 'Diagnosis': 'Classification'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QstPxmc7UwcT"
      },
      "outputs": [],
      "source": [
        "temp = df[\"Classification\"].copy()\n",
        "labels = {df[\"Image Name\"][i]: temp[i][0] for i in range(len(df))}\n",
        "X_test = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yayk3iH0Uyeh"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "for i in os.listdir(tb_path_pos): \n",
        "  if random.randint(1, 20) == 1:\n",
        "    curr = Image.open(tb_path_pos + i)\n",
        "    curr = curr.resize((224,224))\n",
        "    curr = curr.convert(\"L\")\n",
        "    curr = np.stack((curr,)*3)\n",
        "    curr = np.transpose(curr, (1, 2, 0))\n",
        "    curr = PIL.Image.fromarray(curr)\n",
        "    X_test.append(((np.transpose(np.asarray(curr), (2, 1, 0)) / 255), labels[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OG0pp6vU3F3"
      },
      "outputs": [],
      "source": [
        "for i in os.listdir(tb_path_neg):\n",
        "  if random.randint(1, 20) == 1:\n",
        "    curr = Image.open(tb_path_neg + i)\n",
        "    curr = curr.resize((224,224))\n",
        "    curr = curr.convert(\"L\")\n",
        "    curr = np.stack((curr,)*3)\n",
        "    curr = np.transpose(curr, (1, 2, 0))\n",
        "    curr = PIL.Image.fromarray(curr)\n",
        "    X_test.append(((np.transpose(np.asarray(curr), (2, 1, 0)) / 255), labels[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2IoSRYtU3rG"
      },
      "outputs": [],
      "source": [
        "for i in os.listdir(cov1_path_neg):\n",
        "  if \"(\" not in i:\n",
        "    if random.randint(1, 20) == 1:\n",
        "      curr = Image.open(cov1_path_neg + i)\n",
        "      curr = curr.resize((224,224))\n",
        "      curr = curr.convert(\"L\")\n",
        "      curr = np.stack((curr,)*3)\n",
        "      curr = np.transpose(curr, (1, 2, 0))\n",
        "      curr = PIL.Image.fromarray(curr)\n",
        "      X_test.append(((np.transpose(np.asarray(curr), (2, 1, 0)) / 255), labels[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKpfIC_EU42w"
      },
      "outputs": [],
      "source": [
        "for i in os.listdir(cov1_path_opac):\n",
        "  if random.randint(1, 20) == 1:\n",
        "    curr = Image.open(cov1_path_opac + i)\n",
        "    curr = curr.resize((224,224))\n",
        "    curr = curr.convert(\"L\")\n",
        "    curr = np.stack((curr,)*3)\n",
        "    curr = np.transpose(curr, (1, 2, 0))\n",
        "    curr = PIL.Image.fromarray(curr)\n",
        "    X_test.append(((np.transpose(np.asarray(curr), (2, 1, 0)) / 255), labels[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sk3UxCS4U6Cz"
      },
      "outputs": [],
      "source": [
        "for i in os.listdir(cov1_path_vir):\n",
        "  if random.randint(1, 20) == 1:\n",
        "    curr = Image.open(cov1_path_vir + i)\n",
        "    curr = curr.resize((224,224))\n",
        "    curr = curr.convert(\"L\")\n",
        "    curr = np.stack((curr,)*3)\n",
        "    curr = np.transpose(curr, (1, 2, 0))\n",
        "    curr = PIL.Image.fromarray(curr)\n",
        "    X_test.append(((np.transpose(np.asarray(curr), (2, 1, 0)) / 255), labels[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STGIYengU8BC"
      },
      "outputs": [],
      "source": [
        "for i in os.listdir(cov1_path_cov):\n",
        "  if \"(\" not in i:\n",
        "    if random.randint(1, 20) == 1:\n",
        "      curr = Image.open(cov1_path_cov + i)\n",
        "      curr = curr.resize((224,224))\n",
        "      curr = curr.convert(\"L\")\n",
        "      curr = np.stack((curr,)*3)\n",
        "      curr = np.transpose(curr, (1, 2, 0))\n",
        "      curr = PIL.Image.fromarray(curr)\n",
        "      X_test.append(((np.transpose(np.asarray(curr), (2, 1, 0)) / 255), labels[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROYE_9d_U86T",
        "outputId": "8a25d344-70f5-4766-b041-0dcdfef6f2d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/DiseaseDetection/DD Full Dataset/images_001/images/ 141.62361454963684\n",
            "/content/gdrive/MyDrive/DiseaseDetection/DD Full Dataset/images_002/images/ 405.93778014183044\n",
            "/content/gdrive/MyDrive/DiseaseDetection/DD Full Dataset/images_003/images/ 694.7787289619446\n",
            "/content/gdrive/MyDrive/DiseaseDetection/DD Full Dataset/images_004/images/ 976.9530940055847\n",
            "/content/gdrive/MyDrive/DiseaseDetection/DD Full Dataset/images_005/images/ 1259.7463142871857\n",
            "/content/gdrive/MyDrive/DiseaseDetection/DD Full Dataset/images_006/images/ 1532.8629522323608\n",
            "/content/gdrive/MyDrive/DiseaseDetection/DD Full Dataset/images_007/images/ 1806.760930776596\n",
            "/content/gdrive/MyDrive/DiseaseDetection/DD Full Dataset/images_008/images/ 2103.0510246753693\n",
            "/content/gdrive/MyDrive/DiseaseDetection/DD Full Dataset/images_009/images/ 2374.6122653484344\n",
            "/content/gdrive/MyDrive/DiseaseDetection/DD Full Dataset/images_010/images/ 2678.1200416088104\n",
            "/content/gdrive/MyDrive/DiseaseDetection/DD Full Dataset/images_011/images/ 2997.2144045829773\n",
            "/content/gdrive/MyDrive/DiseaseDetection/DD Full Dataset/images_012/images/ 3212.3703660964966\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "for i in dd_paths:\n",
        "  for j in os.listdir(i):\n",
        "    if random.randint(1, 25) == 1:\n",
        "      curr = Image.open(i + j)\n",
        "      curr = curr.resize((224,224))\n",
        "      curr = curr.convert(\"L\")\n",
        "      curr = np.stack((curr,)*3)\n",
        "      curr = np.transpose(curr, (1, 2, 0))\n",
        "      curr = PIL.Image.fromarray(curr)\n",
        "      X_test.append(((np.transpose(np.asarray(curr), (2, 1, 0)) / 255), labels[j]))\n",
        "  print(i, time.time() - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CFsk8SiU-QU"
      },
      "outputs": [],
      "source": [
        "for i in os.listdir(cov2_images):\n",
        "  if random.randint(1, 20) == 1:\n",
        "    curr = Image.open(cov2_images + i)\n",
        "    curr = curr.resize((224,224))\n",
        "    curr = curr.convert(\"L\")\n",
        "    curr = np.stack((curr,)*3)\n",
        "    curr = np.transpose(curr, (1, 2, 0))\n",
        "    curr = PIL.Image.fromarray(curr)\n",
        "    if i in labels:\n",
        "      X_test.append(((np.transpose(np.asarray(curr), (2, 1, 0)) / 255), labels[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pm1fCMmdLqp7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "x_train, x_test, y_train, y_test = train_test_split([i[0] for i in X_test], [i[1] for i in X_test], test_size = 0.2)\n",
        "new_x_train = []\n",
        "for i in range(len(x_train)):\n",
        "  new_x_train.append([x_train[i], y_train[i]])\n",
        "new_x_test = []\n",
        "for i in range(len(x_test)):\n",
        "  new_x_test.append([x_test[i], y_test[i]])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(new_x_train, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(new_x_test, batch_size=len(new_x_test), shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AU54LjEPIvlS"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
        "                        nn.BatchNorm2d(out_channels),\n",
        "                        nn.ReLU())\n",
        "        self.conv2 = nn.Sequential(\n",
        "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
        "                        nn.BatchNorm2d(out_channels))\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU()\n",
        "        self.out_channels = out_channels\n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPJ_T1ttI2IA"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes = 19):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.inplanes = 64\n",
        "        self.conv1 = nn.Sequential(\n",
        "                        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ReLU())\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
        "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
        "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
        "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "        \n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes:\n",
        "            \n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer0(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZx6NljzJtgm"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 16\n",
        "learning_rate = 0.01\n",
        "\n",
        "model = ResNet(ResidualBlock, [3, 4, 6, 3]).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9)  \n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uPC7W54UJvpi",
        "outputId": "cefb2453-cb58-4fdd-d7b5-4d6456d017fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Loss: 1.4277\n",
            "Epoch [2/5], Loss: 1.6370\n",
            "Epoch [3/5], Loss: 1.9519\n",
            "Epoch [4/5], Loss: 2.4378\n",
            "Epoch [5/5], Loss: 1.3208\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images.float())\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        del images, labels, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    print ('Epoch [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, loss.item()))\n",
        "            \n",
        "    # Validation\n",
        "    # with torch.no_grad():\n",
        "    #     correct = 0\n",
        "    #     total = 0\n",
        "    #     for images, labels in valid_loader:\n",
        "    #         images = images.to(device)\n",
        "    #         labels = labels.to(device)\n",
        "    #         outputs = model(images)\n",
        "    #         _, predicted = torch.max(outputs.data, 1)\n",
        "    #         total += labels.size(0)\n",
        "    #         correct += (predicted == labels).sum().item()\n",
        "    #         del images, labels, outputs\n",
        "    \n",
        "    #     print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nhn5YWV8JyG-"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images.float())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the test images: {} %'.format(100 * correct / total))   "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}